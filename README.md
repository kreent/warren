# Warren Screener - VersiÃ³n Optimizada para Cloud Run

## ğŸš€ Mejoras Implementadas

### 1. **CachÃ© en Memoria (Principal mejora)**
- âœ… Resultados del anÃ¡lisis completo se cachean por **1 hora**
- âœ… Listados de S&P500 y Nasdaq-100 se cachean permanentemente (se actualizan raramente)
- âœ… Fundamentales de cada ticker se cachean usando `@lru_cache`
- âœ… **ReducciÃ³n estimada de tiempo: de 4 minutos a ~2-5 segundos** en requests subsecuentes

### 2. **Servidor de ProducciÃ³n (Gunicorn)**
- âœ… Reemplaza el servidor de desarrollo de Flask
- âœ… Configurado con 2 workers y 4 threads
- âœ… Worker class: `gthread` para aprovechar threading
- âœ… Timeout de 300 segundos para anÃ¡lisis inicial
- âœ… Mejor manejo de concurrencia y estabilidad

### 3. **Procesamiento Paralelo**
- âœ… Descarga de histÃ³ricos usando `ThreadPoolExecutor`
- âœ… Hasta 10 descargas simultÃ¡neas (configurable)
- âœ… **ReducciÃ³n de tiempo de descarga: ~60%**

### 4. **Recursos Mejorados**
- âœ… CPU: aumentado a **2 vCPU** (era 1)
- âœ… Memoria: aumentada a **2 GiB** (era 512 MiB)
- âœ… Concurrencia: reducida a **10** (era 80) - mÃ¡s adecuado para scripts CPU-intensivos
- âœ… Startup CPU Boost habilitado

### 5. **Health Checks y Monitoreo**
- âœ… Endpoint `/health` para verificar estado
- âœ… InformaciÃ³n de cachÃ© en respuesta JSON
- âœ… Logs mejorados con timestamps

## ğŸ“Š ComparaciÃ³n de Tiempos Estimados

| Escenario | VersiÃ³n Original | VersiÃ³n Optimizada | Mejora |
|-----------|-----------------|-------------------|--------|
| Primera request (cachÃ© frÃ­o) | ~270 segundos | ~90-120 segundos | ~60% |
| Requests subsecuentes (cachÃ© caliente) | ~270 segundos | ~2-5 segundos | **~98%** |
| Descarga de histÃ³ricos | ~120 segundos | ~40-50 segundos | ~60% |

## ğŸ”§ ConfiguraciÃ³n del CachÃ©

### Ajustar TTL (Time To Live)
En `main_optimized.py`, lÃ­nea 54:
```python
CACHE_TTL_SECONDS = 3600  # 1 hora por defecto
```

**Recomendaciones segÃºn caso de uso:**
- Datos muy dinÃ¡micos (intraday): `300` (5 minutos)
- Datos diarios estÃ¡ndar: `3600` (1 hora) âœ… **Recomendado**
- Datos que cambian poco: `7200` (2 horas)
- Solo necesitas 1 anÃ¡lisis al dÃ­a: `86400` (24 horas)

### Forzar Refresh del CachÃ©
```bash
curl "https://TU-SERVICE-URL/analyze?force_refresh=1"
```

## ğŸ“¦ Archivos del Proyecto

```
proyecto/
â”œâ”€â”€ main_optimized.py      # Script principal optimizado
â”œâ”€â”€ requirements.txt       # Dependencias Python
â”œâ”€â”€ Dockerfile            # ConfiguraciÃ³n Docker
â”œâ”€â”€ cloudrun-config.yaml  # ConfiguraciÃ³n Cloud Run (opcional)
â”œâ”€â”€ deploy.sh             # Script de despliegue automatizado
â””â”€â”€ README.md             # Este archivo
```

## ğŸš€ Instrucciones de Despliegue

### OpciÃ³n 1: Usando el script de despliegue (Recomendado)

1. **Editar configuraciÃ³n:**
   ```bash
   nano deploy.sh
   # Cambiar PROJECT_ID por tu proyecto real
   ```

2. **Hacer ejecutable y desplegar:**
   ```bash
   chmod +x deploy.sh
   ./deploy.sh
   ```

### OpciÃ³n 2: Paso a paso manual

1. **Configurar variables:**
   ```bash
   export PROJECT_ID="tu-proyecto-id"
   export REGION="europe-west1"
   export SERVICE_NAME="warren-screener"
   ```

2. **Construir imagen:**
   ```bash
   docker build -t gcr.io/${PROJECT_ID}/${SERVICE_NAME}:latest .
   ```

3. **Subir a GCR:**
   ```bash
   docker push gcr.io/${PROJECT_ID}/${SERVICE_NAME}:latest
   ```

4. **Desplegar:**
   ```bash
   gcloud run deploy ${SERVICE_NAME} \
     --image gcr.io/${PROJECT_ID}/${SERVICE_NAME}:latest \
     --platform managed \
     --region ${REGION} \
     --allow-unauthenticated \
     --cpu 2 \
     --memory 2Gi \
     --timeout 300 \
     --concurrency 10 \
     --max-instances 20 \
     --port 8080
   ```

## ğŸ” Endpoints Disponibles

### 1. InformaciÃ³n del servicio
```bash
GET /
```
Retorna informaciÃ³n sobre el servicio y las optimizaciones aplicadas.

### 2. AnÃ¡lisis principal (con cachÃ©)
```bash
GET /analyze
```
Retorna el anÃ¡lisis. Si el cachÃ© es vÃ¡lido (< 1 hora), responde inmediatamente.

**Respuesta incluye:**
```json
{
  "total_analyzed": 150,
  "candidates_count": 25,
  "top_10": [...],
  "cached_at": "2024-01-15T10:30:00",
  "cache_ttl_seconds": 3600,
  "from_cache": true,
  "cache_age_seconds": 245
}
```

### 3. Forzar nuevo anÃ¡lisis
```bash
GET /analyze?force_refresh=1
```
Invalida el cachÃ© y ejecuta un nuevo anÃ¡lisis completo.

### 4. Health check
```bash
GET /health
```
Verifica que el servicio estÃ¡ funcionando.

## ğŸ“ˆ Monitoreo

### Ver logs en tiempo real:
```bash
gcloud logging tail "resource.type=cloud_run_revision AND resource.labels.service_name=warren-screener" --format json
```

### Ver Ãºltimos 50 logs:
```bash
gcloud logging read "resource.type=cloud_run_revision AND resource.labels.service_name=warren-screener" --limit 50
```

### Ver mÃ©tricas en Cloud Console:
1. Ir a Cloud Run â†’ warren-screener
2. PestaÃ±a "METRICS"
3. Revisar:
   - Latencia (deberÃ­a bajar drÃ¡sticamente)
   - Request count
   - CPU y Memory utilization

## ğŸ¯ Optimizaciones Adicionales Futuras

Si aÃºn necesitas mÃ¡s velocidad, considera:

### 1. **Memorystore for Redis** (CachÃ© distribuido)
- Para compartir cachÃ© entre mÃºltiples instancias
- Persistencia del cachÃ© aunque las instancias se reinicien
- Ver guÃ­a en el documento original

### 2. **Cloud Tasks para anÃ¡lisis asÃ­ncrono**
- Ejecutar anÃ¡lisis en background
- Retornar inmediatamente un ID de tarea
- Consultar resultados despuÃ©s

### 3. **BigQuery para almacenar resultados**
- Guardar anÃ¡lisis histÃ³ricos
- Queries rÃ¡pidas sobre datos pasados
- Analytics avanzados

### 4. **Reducir universo de tickers**
- Cambiar `UNIVERSE_LIMIT = 250` a `150` o menos
- AnÃ¡lisis mÃ¡s rÃ¡pido con menos tickers

## ğŸ› Troubleshooting

### Error: Timeout despuÃ©s de 300 segundos
**SoluciÃ³n:** Incrementar timeout en deploy:
```bash
--timeout 600  # 10 minutos
```

### Error: Out of Memory
**SoluciÃ³n:** Aumentar memoria:
```bash
--memory 4Gi
```

### CachÃ© no funciona entre requests
**Causa:** Cloud Run escala a cero y cada nueva instancia tiene cachÃ© vacÃ­o.
**SoluciÃ³n:** Configurar instancias mÃ­nimas:
```bash
--min-instances 1
```

### AnÃ¡lisis sigue siendo lento en primera request
**Opciones:**
1. Reducir `UNIVERSE_LIMIT` (lÃ­nea 21 del cÃ³digo)
2. Reducir `MAX_FUND_REQS` (lÃ­nea 23 del cÃ³digo)
3. Aumentar workers de Gunicorn en Dockerfile

## ğŸ’¡ Consejos Pro

1. **Warm-up automÃ¡tico:** Configurar Cloud Scheduler para llamar `/analyze` cada 50 minutos mantiene el cachÃ© caliente.

2. **Monitorear uso de cachÃ©:** Revisar el campo `from_cache` en las respuestas para verificar efectividad.

3. **Ajustar concurrencia:** Si el anÃ¡lisis es muy CPU-intensivo, reducir a `--concurrency 5` o menos.

4. **Costos:** Con cachÃ©, la mayorÃ­a de requests responden en segundos â†’ menores costos de CPU.

## ğŸ“ Soporte

Si tienes dudas sobre la implementaciÃ³n o necesitas ajustes adicionales, revisa:
- Logs de Cloud Run
- MÃ©tricas de latencia
- Campo `from_cache` en respuestas

Â¡Buena suerte con tu screener optimizado! ğŸš€
